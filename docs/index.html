<!DOCTYPE html>
<html>
<head>
  <!--
    If you are serving your web app in a path other than the root, change the
    href value below to reflect the base path you are serving from.

    The path provided below has to start and end with a slash "/" in order for
    it to work correctly.

    For more details:
    * https://developer.mozilla.org/en-US/docs/Web/HTML/Element/base

     placeholder for base href that will be replaced by the value of
    the `--base-href` argument provided to `flutter build`.
  -->
  <base href="/cnxdev.github.io/">

  <meta charset="UTF-8">
  <meta content="IE=Edge" http-equiv="X-UA-Compatible">
  <meta name="description" content="A new Flutter project.">

  <!-- iOS meta tags & icons -->
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="apple-mobile-web-app-title" content="travel_together">
  <link rel="apple-touch-icon" href="icons/Icon-192.png">

  <!-- Favicon -->
  <link rel="icon" type="image/png" href="favicon.png"/>

  <title>travel_together</title>
  <link rel="manifest" href="manifest.json">
  <script src="https://cdn.jsdelivr.net/npm/face-api.js/dist/face-api.min.js"></script>
</head>
<body>
<script src="https://maps.googleapis.com/maps/api/js?key="></script>
  <script src='https://unpkg.com/tesseract.js@v4.0.2/dist/tesseract.min.js'></script>
  <script>
    async function _extractText(imagePath , mapData){
      var worker = await Tesseract.createWorker();
      await worker.load();
      await worker.loadLanguage(mapData.language)
      await worker.initialize(mapData.language)
      await worker.setParameters(mapData.args)
      var rtn = await worker.recognize(imagePath, {}, worker.id);
      await worker.terminate();
      if(mapData.args["tessjs_create_hocr"]){
        return rtn.data.hocr;
      }
      return rtn.data.text;
    }
  </script>
  <script src="flutter_bootstrap.js" async></script>
  <script>
    // ฟังก์ชัน JavaScript สำหรับโหลดโมเดลและตรวจจับใบหน้า
    async function loadFaceApiModels() {
      await faceapi.nets.tinyFaceDetector.loadFromUri('/models');
      await faceapi.nets.faceLandmark68Net.loadFromUri('/models');
      await faceapi.nets.faceRecognitionNet.loadFromUri('/models');
      console.log('FaceAPI models loaded');
    }

    // สร้างการแสดงภาพจากกล้อง
    // async function startVideo() {
    //   const video = document.getElementById('video');
    //   const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
    //   video.srcObject = stream;
    // }

    // ฟังก์ชันจับใบหน้าและบันทึก Face Descriptor
    async function captureFace() {
      const video = document.getElementById('video');
      const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceDescriptors();
      
      if (detections.length > 0) {
        const faceDescriptor = detections[0].descriptor;  // เอา Face Descriptor ของใบหน้าที่ตรวจจับได้
        localStorage.setItem('userFaceDescriptor', JSON.stringify(Array.from(faceDescriptor)));
        
        // แสดงสถานะ
        document.getElementById('status').textContent = 'Face captured and saved!';
      } else {
        document.getElementById('status').textContent = 'No face detected. Please try again.';
      }
    }

    // เรียกใช้ฟังก์ชันเมื่อหน้าต่างโหลดเสร็จ
    async function detectFacesFromVideo(videoElement) {
    setInterval(async () => {
      const detections = await faceapi.detectAllFaces(videoElement, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceDescriptors(); // Ensure that face descriptors are included

        analyzeFaceAngle(detections);

     

      // ส่งผลลัพธ์ไป Flutter Web
      const event = new CustomEvent('face-detection-result', {
        detail: JSON.stringify(detections)
      });
      window.dispatchEvent(event);
    }, 500);
  }

  function distance(point1, point2) {
    return Math.sqrt(Math.pow(point1.x - point2.x, 2) + Math.pow(point1.y - point2.y, 2));
}
    async function detectFaces(imageElement) {
    try {
      console.log('Detecting faces in image:', imageElement.src); 
      const options = new faceapi.TinyFaceDetectorOptions({
        inputSize: 512,
        scoreThreshold: 0.5,
      });

      const detections = await faceapi.detectAllFaces(imageElement, options)
        .withFaceLandmarks()
        .withFaceDescriptors(); 

      console.log('Detections:', detections);
      
      // ส่งผลลัพธ์ไป Flutter Web
      window.dispatchEvent(new CustomEvent('face-detection-face', {
        detail: JSON.stringify(detections)
      }));

      return detections;
    } catch (error) {
      console.error('Error detecting faces:', error);
      window.postMessage({
        type: 'face-detection-error',
        data: error.message
      }, '*');

      return [];
    }
  }


//   async function detectFacesFromVideo(videoElement) {
//     setInterval(async () => {
//         const detections = await faceapi.detectAllFaces(videoElement, new faceapi.TinyFaceDetectorOptions());
//         const event = new CustomEvent('face-detection-result', { detail: JSON.stringify(detections) });
//         window.dispatchEvent(event);
//     }, 500);
//     }

//     async function detectFaces(imageElement) {
//   try {
//     console.log('Detecting faces in image:', imageElement.src); 
//     const options = new faceapi.TinyFaceDetectorOptions({
//       inputSize: 512,
//       scoreThreshold: 0.5,
//     });

//     const detections = await faceapi.detectAllFaces(imageElement, options);
    
//     console.log('Detections:', detections);
    
//     // ส่งผลลัพธ์ไป Flutter Web
//     window.dispatchEvent(new CustomEvent('face-detection-result', {
//   detail: JSON.stringify(detections)
// }));

//     return detections;
//   } catch (error) {
//     console.error('Error detecting faces:', error);

//     window.postMessage({
//       type: 'face-detection-error',
//       data: error.message
//     }, '*');

//     return [];
//   }
// }

async function analyzeFaceAngle(detections) {
  if (detections.length === 0) {
        return;
    }

  
          
    const landmarks = detections[0].landmarks;
    const nose = landmarks.getNose();  // จุดของจมูก
    const leftEye = landmarks.getLeftEye(); // จุดตาซ้าย
    const rightEye = landmarks.getRightEye(); // จุดตาขวา
    const jaw = landmarks.getJawOutline(); // แนวกราม

    const noseX = nose[0].x;  // พิกัด x ของจมูก
    const leftEyeX = leftEye[0].x;  // พิกัด x ของตาซ้าย
    const rightEyeX = rightEye[0].x;  // พิกัด x ของตาขวา

    const eyeCenterX = (leftEyeX + rightEyeX) / 2; // จุดกึ่งกลางระหว่างตา
    const leftThreshold = leftEyeX + (eyeCenterX - leftEyeX) * 1.3; // 40% ทางซ้ายของจุดกลาง
    const rightThreshold = rightEyeX - (rightEyeX - eyeCenterX) * 0.53; // 40% ทางขวาของจุดกลาง
    // คำนวณค่าความชันของเส้นระหว่างดวงตา (เอียงซ้าย/ขวา)
    const eyeSlope = (rightEye[0].y - leftEye[0].y) / (rightEye[0].x - leftEye[0].x);

    // คำนวณว่าเงยหน้าหรือก้มหน้าโดยใช้ปลายจมูกและแนวกราม

    const noseY = nose[nose.length - 1].y;  // ปลายจมูก
    const chinY = jaw[jaw.length - 1].y;  // คาง
    
    let faceDirection = "ตรง"; // ค่าปกติ
    
    if (noseY < chinY +45) {
        faceDirection = "เงยหน้า"; // เงยหน้า
    } else if (noseY > chinY + 80) {
        faceDirection = "ก้มหน้า"; // ก้มหน้า
    } else if (noseX < leftThreshold) {
    faceDirection = "หันไปทางซ้าย";
    } else if (noseX > rightThreshold) {
        faceDirection = "หันไปทางขวา";
    } 
      
    
    // แสดงผลแนะนำการปรับตำแหน่งหน้า
    let message = '';
    if (faceDirection === 'หันไปทางขวา') {
        message = 'กรุณาหันหน้ามาทางขวา';
    } else if (faceDirection === 'หันไปทางซ้าย') {
        message = 'กรุณาหันหน้ามาทางซ้าย';
    } else if (faceDirection === 'ก้มหน้า') {
        message = 'กรุณายกหน้าขึ้น';
    } else if (faceDirection === 'เงยหน้า') {
        message = 'กรุณาก้มหน้าลง';
    } else {
        message = 'หน้าของคุณอยู่ในตำแหน่งที่ถูกต้อง';
    }
   

    function getEAR(eye) {
                const A = distance(eye[1], eye[5]); // ระยะห่างแนวตั้ง
                const B = distance(eye[2], eye[4]);
                const C = distance(eye[0], eye[3]); // ระยะห่างแนวนอน
                return (A + B) / (2.0 * C); // ค่า EAR
            }

            const leftEAR = getEAR(leftEye);
            const rightEAR = getEAR(rightEye);
            const ear = (leftEAR + rightEAR) / 2.0;

    // console.log(message);
    const faceData = {
        nose: nose,  // จุดของจมูก
        leftEye: leftEye,  // จุดของตาซ้าย
        rightEye: rightEye,  // จุดของตาขวา
        jaw: jaw,  // แนวกราม
    };
    // ส่งผลลัพธ์ไป Flutter Web
    setTimeout(() => {
    // ส่งผลลัพธ์ไป Flutter Web
    window.postMessage({
        type: "face-landmark-detection",
        faceDirection: faceDirection,
        message: message, // ส่งข้อความแนะนำการปรับตำแหน่งหน้า
        data: faceData,
        blinking : ear
    }, "*");
}, 2000); 

}


function delay(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
}

window.onload = async () => {
      await loadFaceApiModels();
      await startVideo();

      document.getElementById('captureButton').addEventListener('click', captureFace);
    };


  </script>
</body>
</html>
